{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite Plugin Code Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intended Audience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "This lab is for people who want to learn how to write and execute a Plaso plugin in Python.  This tutorial assumes:\n",
    "\n",
    "+  You have a functional development environment\n",
    "+  You have used Plaso\n",
    "+  You are familiar with the Python programming language\n",
    "+  You are looking to write a plugin (as an opposed to a parser, which is covered in a separate codelab)\n",
    "\n",
    "## Objective\n",
    "\n",
    "This lab will teach you how to write a SQLite database plugin with tests for the Plaso framework.  By the end you will be able to:\n",
    "\n",
    "+ Write a SQLite database plugin for plaso\n",
    "+ Write unit tests for the plugin\n",
    "+ Run the plugin as part of plaso/log2timeline\n",
    "\n",
    "## Expectations\n",
    "\n",
    "This lab should take you a couple hours to complete.  Some of this is dependent entirely on strange build issues you might have.  We are not attempting to get you to check in code yet, this is more to demonstrate how a plugin is written. For this to be a checked in plugin you need to write a plugin against a SQLite database that is not already parsed and split the code here into several files (layout explained below).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to writing a Plaso plugin!  From the outside, writing a plugin can be daunting, but once you get your dev environment going, you've fought half the battle.  This code lab features a simple SQLite database plugin, but the formula can be used for any type of plugins (another codelab demonstrates a Windows Registry plugin) and the hope is that with these two codelabs we should have the plugin writing more or less covered). You may also be interested in the text parser codelab.\n",
    "\n",
    "## Before Starting\n",
    "\n",
    "Get familiar with the [developers guide](https://github.com/log2timeline/plaso/wiki/Developers-Guide) and more specifically the [style guide](https://github.com/log2timeline/plaso/wiki/Style-guide). To make the code easier to maintain we follow a style guide, partially based on the [Google Python Style Guide](http://google-styleguide.googlecode.com/svn/trunk/pyguide.html) but slightly modified to fit our needs.\n",
    "\n",
    "We also follow a code review process that is discussed on the [code review](https://github.com/log2timeline/plaso/wiki/Codereview) site.\n",
    "\n",
    "This is an iPython notebook, and if you are not familiar with it then here is the brief introduction. This is basically an iPython shell wrapped up in a pretty GUI (browser window). You can execute any Python code you wish, and quickly go back, edit and re-run code. To run the code, click the window with the code segment and press \"Shift+Enter\", that way you will see that the bracket on the left will change to indicate it has been executed and you may see some output below (if the code segment produced any output).\n",
    "\n",
    "One thing to make note of is that some of the code segments depend on previous code segments having been executed. So in order for this codelab to work properly you need to execute **EVERY** code segment that is presented here, especially all class declarations and import statements, but to be sure just execute them all [except those explicitly stated as **optional**].\n",
    "\n",
    "The first thing we need to do is to make sure your development environment is up-to date. Run the following code snippet (below) by clicking the tab and pressing \"**SHIFT-ENTER**\". If you'll see a printed warning start by upgrading the tool before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "# Let's put this in a method so we can easily call it from other parts of the codelab.\n",
    "def PrintClassHelp(class_object, filter_string=''):\n",
    "  \"\"\"Prints a help string for a given class object.\n",
    "\n",
    "  Args:\n",
    "    class_object: The class that we are about to inspect.\n",
    "    filter_string: Filter class members that start with a particular string.\n",
    "  \"\"\"\n",
    "  # Print the docstring of the class.\n",
    "  print u''\n",
    "  print class_object.__doc__\n",
    "   \n",
    "  # Print information for every member function.\n",
    "  additional_members = []\n",
    "  for member_name, member_value in inspect.getmembers(class_object):\n",
    "    # Check to see if we are filtering out members starting with\n",
    "    # a particular string.\n",
    "    if filter_string and not member_name.startswith(filter_string):\n",
    "      continue\n",
    "    if inspect.ismethod(member_value):\n",
    "      args = inspect.getargspec(member_value)\n",
    "      doc_string = member_value.__doc__\n",
    "        \n",
    "      print u'{0}{1:>20s}({2}){0:>10}\\n\\n{3}\\n{4}\\n\\n'.format(\n",
    "          '*'*5, member_name, u','.join(args.args), doc_string, '-'*80)\n",
    "    else:\n",
    "      if member_name.startswith('_'):\n",
    "        continue\n",
    "      if member_name in ['classes', 'parent_class', 'plugin_feature', 'top_level_class']:\n",
    "        continue\n",
    "        \n",
    "      additional_members.append(u'{} = {}'.format(member_name, repr(member_value)))\n",
    "\n",
    "  if additional_members:\n",
    "    print '\\n'\n",
    "    print '*** Additional Members of Class ***\\n\\n ',\n",
    "    print u'\\n  '.join(additional_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "During this codelab we will be using the iPython notebook interface for everything, which means we have all the classes and code in a single file. Once we deploy the code to the actual codebase we would need to save the code in several places, typically something like:\n",
    "\n",
    "+ plaso/parsers/sqlite_plugins/myplugin.py\n",
    "+ tests/parsers/sqlite_plugins/myplugin.py\n",
    "+ plaso/formatters/myplugin.py\n",
    "+ tests/formatters/myplugin.py\n",
    "\n",
    "You will likely also want to change the **plaso/frontend/presets.py** to include the plugin in a preset. This still really depends on the plugin itself, sometimes you want to include the parser and all its plugins (like the case of Windows registry plugins), sometimes you only want to load specific plugin(s), which is typically the case with SQLite plugins.\n",
    "\n",
    "We are however omitting all these details to make the codelab easier to follow along. This can also be used for people to test their plugins and play with them without the need to mess with the codebase and once the plugin is fully functional then create the necessary files and start the code review process.\n",
    "\n",
    "There are also a lot of comments in the code in this codelab that would typically be omitted from a released plugin. To see the actual code that is used as an example here click on one of the below links (we will only be using parts of that code for demonstration):\n",
    "\n",
    "+ [plaso/parsers/sqlite_plugins/skype.py](https://github.com/log2timeline/plaso/blob/master/plaso/parsers/sqlite_plugins/skype.py)\n",
    "+ [plaso/parsers/sqlite_plugins/skype_test.py](https://github.com/log2timeline/plaso/blob/master/plaso/parsers/sqlite_plugins/skype_test.py)\n",
    "\n",
    "## Writing the Plugin\n",
    "\n",
    "We are going to write the plugin completely in this iPython notebook, and test it there too. There is no need for anything else than this notebook, a sample registry file and the plaso libs available.\n",
    "\n",
    "Before writing a plugin, and now we are assuming we are attempting parse a particular SQLite database, ask yourself these questions:\n",
    "\n",
    "+ Examine the database itself, what are the table names?\n",
    "+ What tables provide the information I'm trying to extract?\n",
    "+ Has there been a change in table names, and schema in different versions?\n",
    "+ Do I need to support older versions?\n",
    "+ What does the schema look like for the tables that I'm interested in?\n",
    "+ Are there any relations between the tables that I need to be aware of?\n",
    "+ How are the timestamps formatted? And where are they stored?\n",
    "+ Are there any defined \"VIEWS\" in the table that can help me understand the schema and how it is used?\n",
    "+ Create the SQL commands and execute them using something like sqlite3 to test them first.\n",
    "\n",
    "Remember that we are not about to submit this plugin in for review, since it is already checked in, this is only for demonstration purposes, please refer to the [plaso roadmap](https://docs.google.com/a/kiddaland.net/spreadsheet/ccc?key=0An0H7z4S52FldFFuQ2tHRDRsaEdzeDRBVXN5SXNfRnc#gid=0) for open parser/plugin assignments (or add your own).\n",
    "\n",
    "Before we start looking at the code we need to download the SQLite database to a temporary location so that we can use it for the remainder of this codelab. For this you need an Internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import a library to make the HTTP connection.\n",
    "import urllib2\n",
    "\n",
    "# Import a library so that we can create a temporary file.\n",
    "import tempfile\n",
    "\n",
    "# The URL to the SYSTEM hive we are about to use for our testing.\n",
    "url = u'https://github.com/log2timeline/plaso/raw/master/test_data/skype_main.db'\n",
    "\n",
    "# Download the file.\n",
    "response = urllib2.urlopen(url)\n",
    "data = response.read()\n",
    "\n",
    "# Save it in a temporary file (we don't want it to be deleted).\n",
    "test_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "\n",
    "# Save the name since that is what we will refer to later in the code.\n",
    "test_database_path = test_file.name\n",
    "\n",
    "print 'Wrote test database file to {0:s}'.format(test_database_path)\n",
    "\n",
    "# Write data to it.\n",
    "test_file.write(data)\n",
    "\n",
    "# Close the file.\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The header\n",
    "\n",
    "First things first, every file checked into the project needs a header. That header contains among other a docstring as well as import statements.\n",
    "\n",
    "The first line should be an encoding defintion. After that there is a doc string that needs to be created, it should not be longer than 80 characters in width. If you need more than a single line to describe the parser please still only use max 80 characters as the first line, ending with a dot. Then you can create a more detailed\n",
    "description two lines down (an example of that can be seen below).\n",
    "\n",
    "The import order is defined in the [style guide](http://google-styleguide.googlecode.com/svn/trunk/pyguide.html?showone=Imports_formatting#Imports_formatting):\n",
    "\n",
    "    Imports are always put at the top of the file, just after any module comments and doc strings and before module globals and constants. \n",
    "    Imports should be grouped with the order being most generic to least generic:\n",
    "\n",
    "    + standard library imports\n",
    "    + third-party imports\n",
    "    + application-specific imports\n",
    "\n",
    "    Within each grouping, imports should be sorted lexicographically, ignoring case, according to each module's full package path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"This file contains a basic Skype SQLite parser.\"\"\"\n",
    "import logging\n",
    "\n",
    "# We need to be able to create new event objects, and more specifically\n",
    "# get access to timestamped events.\n",
    "from plaso.events import time_events\n",
    "\n",
    "# Import the SQLite parser itself.\n",
    "from plaso.parsers import sqlite as sqlite_parser\n",
    "\n",
    "# Import the interface for all SQLite database plugins.\n",
    "from plaso.parsers.sqlite_plugins import interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "### The Plugin Class\n",
    "\n",
    "We know need to know what kind of plugin you are trying to implement. For now we know we are trying to parse a specific SQLite database using a plugin. If we look at the [SQLite database interface section](https://sites.google.com/a/kiddaland.net/plaso/developer/parsers/write-a-plugin/sqlite) we notice that the plugin interface is set up relatively simple.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print PrintClassHelp(interface.SQLitePlugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a database file object from the file we just downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries from dfVFS so we can open up the file.\n",
    "from dfvfs.lib import definitions\n",
    "from dfvfs.path import factory as path_spec_factory\n",
    "from dfvfs.resolver import resolver as path_spec_resolver\n",
    "\n",
    "# Find the file and get a handle to it.\n",
    "path_spec = path_spec_factory.Factory.NewPathSpec(\n",
    "    definitions.TYPE_INDICATOR_OS, location=test_database_path)\n",
    "file_entry = path_spec_resolver.Resolver.OpenFileEntry(path_spec)\n",
    "\n",
    "# Open up the SQLite database.\n",
    "database = sqlite_parser.SQLiteDatabase(file_entry.name)\n",
    "database.Open(file_entry.GetFileObject())\n",
    "\n",
    "# Create a SQLite cache object.\n",
    "database_cache = sqlite_parser.SQLiteCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got the database opened for future use and we can start exploring it. Let's look at what tables are in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The SQL command we need to issue to get table names.\n",
    "table_sql = 'SELECT name FROM sqlite_master WHERE type=\"table\"'\n",
    "\n",
    "# Create a little method that we can later re-use here to execute SQL commands and get the results back.\n",
    "def QueryForResults(sql_command):\n",
    "    \"\"\"Execute a SQLite database query and return back a generator of results.\"\"\"\n",
    "    results = database.Query(sql_command)\n",
    "    for row in results:\n",
    "        yield row\n",
    "        \n",
    "print '*'*40 + ' TABLES ' + '*'*40\n",
    "for row in QueryForResults(table_sql):\n",
    "    print u'  + ',\n",
    "    print row[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few tables there that could be of an assistance to us. Let's look at the table definition, or the schema of these tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in QueryForResults('SELECT name, sql FROM sqlite_master WHERE type=\"table\"'):\n",
    "    print u'{0}  {1}  {0}'.format('*'*10, row[0])\n",
    "    print row[1]\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for any values there that may have timestamps associated to them or otherwise could provide us with value. \n",
    "\n",
    "We can also look for VIEW tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in QueryForResults('SELECT name, sql FROM sqlite_master WHERE type=\"view\"'):\n",
    "    print u'{0}  {1}  {0}'.format('*', row[0])\n",
    "    print row[1]\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the tables above we may have spotted the tables Chats and Messages... let's review them a bit more.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in QueryForResults('SELECT name, sql FROM sqlite_master WHERE type = \"table\" AND (name = \"Chats\" OR name = \"Messages\")'):\n",
    "    print u'{0}  Table: {1}  {0}'.format('*'*10, row[0])\n",
    "    #white_space = len('CREATE TABLE {} ('.format(row[0])) - 1\n",
    "    sql_string = row[1].replace('(', '(\\n    ')\n",
    "    print u'\\n   '.join(sql_string.split(','))\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting these above tables can lead us to a SQL query like the one below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chat_query = (\n",
    "    'SELECT c.id, c.participants, c.friendlyname AS title, '\n",
    "    'm.author AS author, m.from_dispname AS from_displayname, '\n",
    "    'm.body_xml, m.timestamp, c.dialog_partner FROM Chats c, Messages m '\n",
    "    'WHERE c.name = m.chatname')\n",
    "\n",
    "for index, row in enumerate(QueryForResults(chat_query)):\n",
    "  print '-'*80\n",
    "  print '      ROW RESULT: {}'.format(index)\n",
    "  print '-'*80\n",
    "  for key in row.keys():\n",
    "    print u'{} -> {}'.format(key, row[key])\n",
    "  print '*'*80\n",
    "  print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*One important disclaimer, since we are taking an already checked in plugin to use as an example, to avoid all namespace collitions we are appending the word \"Foo\" or \"foo\" to many of the class names and other fields.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Class Constants\n",
    "\n",
    "In plaso terms as soon as we've got more than a single \"parser\" that attempts to parse a particular file format we convert that to a plugin system. Then a very generic parser can be created that takes care of all file format parsing, leaving the plugins to do minimal work, just defining few class constants that are used to match the particular file or file segments to what the plugin is designed to parse and then a function to process the data collected.\n",
    "\n",
    "For SQLite database plugins we need to define the following class attributes:\n",
    "\n",
    "+ **NAME**: Name of the plugin, this should be short and concise but still descriptive. Something like \"skype\" or \"chrome\", etc.\n",
    "+ **DESCRIPTION**: A short description of what the plugin does, eg: \"SQLite plugin for Skype main.db SQLite database file.\"\n",
    "+ **QUERIES**: This is a list of all the SQL commands that should be run on the database and the name of the call back method we need to call with the query results.\n",
    "+ **REQUIRED_TABLES**: The parser itself will determine if we are trying to parse a SQLite database. However, since there are so many SQLite databases out there we need some additional information to determine if this particular plugin should be executed. For that we need a list (technically a frozenset) of the table names that need to be defined in the database for this plugin to be considered.\n",
    "+ **URLS**: [**OPTIONAL**] This is a list of URL's that can be used to read additional information about this particular registry key. Preferably, this is a link to a page on [forensics wiki](http://forensicswiki.org/wiki/Main_Page) discussing the format, but this could also be a link to some blogs discussing how to interpret the database, or a link to the developer of the database discussing the structure, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call back functions\n",
    "\n",
    "The underlying parser takes care of opening the database, querying the available tables and comparing that list to the list provided in the REQUIRED_TABLES. If that list is determined as a subset of the actual tables the parser takes the queries defined in QUERIES and executes them one-by-one on the database.\n",
    "\n",
    "For every row that comes out of each query the parser calls the named call back function that is defined in the QUERIES list with the row, cache object and potentially other objects as well.\n",
    "\n",
    "For instance, if we define the SQL command:\n",
    "\n",
    "    QUERIES = [('SELECT foo FROM bar', 'ParseFoo')]\n",
    "\n",
    "Then the parser executes the command \"SELECT foo FROM bar\" and for every result that comes from that the function \"ParseFoo\" is called. This call back function needs to be defined in the plugin and accept the correct parameters:\n",
    "\n",
    "    def ParseFoo(self, parser_mediator, row, query=None, **unused_kwargs):\n",
    "\n",
    "Or if you need access to a database cache object:\n",
    "\n",
    "    def ParseFoo(self, parser_mediator, row, query=None, cache=None, **unused_kwargs):\n",
    "\n",
    "The SQLite database cache object that gets passed as a parameter to each SQLite call back function is an object that can be used to store cached data that you may need. Let's imagine a scenario... \n",
    "\n",
    "A database table defines a list of paths and filenames. Each row in the database contains the file name and an identification value for the parent value. To fully construct the path one would need to follow that parent id, query the database for that ID value, and see if that entry had a parent, etc. Some of this could be achieved using complex JOIN statements in SQLite, however sometimes it is just easier to run a single SQL command to get all these values, store that as a cache and then quickly look up values in the cache when needed.\n",
    "\n",
    "That is what the cache object can be used for. Let's look at the definition for the cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PrintClassHelp(sqlite_parser.SQLiteCache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one example on how to use the cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create new cache instance.\n",
    "another_cache = sqlite_parser.SQLiteCache()\n",
    "\n",
    "# Create a SQL command we would like to issue to the database and cache the results of.\n",
    "sql_command = u'SELECT parent_id, partner_handle AS skypeid, partner_dispname AS skypename FROM transfers'\n",
    "\n",
    "# Execute the SQL command and get back a result set.\n",
    "results = database.Query(sql_command)\n",
    "\n",
    "# And now we can populate the cache based on that result set.\n",
    "# This gets explained a bit more later on.\n",
    "another_cache.CacheQueryResults(\n",
    "    results, 'destination', 'parent_id', ('skypeid', 'skypename'))\n",
    "\n",
    "# And fetch the recently added entry here.\n",
    "destination_dict  = another_cache.GetResults('destination')\n",
    "\n",
    "print destination_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to better understand the CacheQueryResults function let's print the docstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PrintClassHelp(another_cache.CacheQueryResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so let's go back to that code of ours and see how that builds up that cache dict object:\n",
    "\n",
    "    cache.CacheQueryResults(\n",
    "        results, 'destination', 'parent_id', ('skypeid', 'skypename'))\n",
    "\n",
    "We call the function with the parameters set as:\n",
    "\n",
    "+ **sql_results**: *results*. We need to first issue the database query, get the results back and pass that object in.\n",
    "+ **attribute_name**: *'destination'*. This is the name of the attribute we would like to store the results as in the cache.\n",
    "+ **key_name**: *'parent_id'*. This is the name of the row key we would like to use as key in the resulting dict that will be created.\n",
    "+ **values**: *('skypeid', 'skypname')*. This is the list (or single value) of row keys that we would like to be used as values in the resulting dict that is created.\n",
    "\n",
    "To go over this specific example, what we are asking the cache to do is to create a dict object that is called \"destination\" and store the results from each row in that in the following way:\n",
    "\n",
    "    cache.destination = {}\n",
    "    for row in results:\n",
    "        cache.destination[row['parent_id']] = (row['skypeid'], row['skypename'])\n",
    "\n",
    "This is roughly what happens. What we end up is a dict that we can use based on the \"parent_id\" and it will give us the appropriate values for \"skypid\" and \"skypename\".\n",
    "\n",
    "An example here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skype_id, skype_name =  destination_dict.get(23445435)\n",
    "\n",
    "print u'ID: {}\\nNAME: {}'.format(skype_id, skype_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timestamp\n",
    "\n",
    "When dealing with the SQLite databases timestamps come in all shapes and formats. One of the more common format is POSIX time or Epoch time in UTC. However that may or may not be the case for the database you are examining.\n",
    "\n",
    "Let's examine what our options are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the library we are about to inspect.\n",
    "from plaso.lib import timelib\n",
    "\n",
    "# You can easily change the name of the class here if you want to explore a different\n",
    "# class and it's members.\n",
    "PrintClassHelp(timelib.Timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Object\n",
    "\n",
    "Each timestamped event is described as an EventObject. Often it may be easier to create a convenience class to make it easier to create the EventObject.\n",
    "\n",
    "Let's examine one such example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SkypeChatEvent(time_events.PosixTimeEvent):\n",
    "  \"\"\"Convenience class for a Skype event.\"\"\"\n",
    "\n",
    "  # Define the data type, this is very important and needs to have a 1:1\n",
    "  # mapping to the formatter for the event.\n",
    "  DATA_TYPE = 'skype:event:chat'\n",
    "\n",
    "  def __init__(self, row, to_account):\n",
    "    \"\"\"Build a Skype Event from a single row.\n",
    "\n",
    "    Args:\n",
    "      row: A row object (instance of sqlite3.Row) that contains the\n",
    "           extracted data from a single row in the database.\n",
    "      to_account: A string containing the accounts (excluding the\n",
    "                  author) of the conversation.\n",
    "    \"\"\"\n",
    "    # First thing we need to do is to call the \"super\" class or the parent\n",
    "    # of the event. This particular event object inherits from a class\n",
    "    # called event.PosixTimeEvent, which expects the timestamp sent to\n",
    "    # it to be POSIX or Epoch in UTC.\n",
    "    # The parameters that need to be passed to the PosixTimeEvent are:\n",
    "    #    timestamp: Timestamp in POSIX or Epoch since UTC.\n",
    "    #    timestamp_desc: Description of the timestamp, eg \"Last Written Time\".\n",
    "    #    data_type: The data type of this event object.\n",
    "    super(SkypeChatEvent, self).__init__(\n",
    "        row['timestamp'], 'Chat from Skype', self.DATA_TYPE)\n",
    "\n",
    "    # We can now set other attributes that we need in order to better format\n",
    "    # the message. These attributes vary depending on the source they come from.\n",
    "    self.title = row['title']\n",
    "    self.text = row['body_xml']\n",
    "    self.from_account = u'{0:s} <{1:s}>'.format(\n",
    "        row['from_displayname'], row['author'])\n",
    "    self.to_account = to_account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The event object is pretty simple really. We need to set the following keys:\n",
    "\n",
    "+ **row**: FOO\n",
    "+ **to_account**: FOO\n",
    "\n",
    "This inherits from event.PosixTimeEvent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PrintClassHelp(time_events.PosixTimeEvent, '__init__')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parent class needs the following parameters:\n",
    "\n",
    "+ **posix_time**: The timestamp in POSIX time, or Epoch time (in UTC).\n",
    "+ **timestamp_description**: This is the description of the meaning of the timestamp, eg: \"Last Written\", \"Entry Created\".\n",
    "+ **data_type**: The data type of the EventObject, that needs to be a 1:1 mapping between what is defined in the formatter for this event object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we just need to define the rest of the needed EventObjects for the plugin to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SkypeAccountEvent(time_events.PosixTimeEvent):\n",
    "  \"\"\"Convenience class for account information.\"\"\"\n",
    "\n",
    "  DATA_TYPE = 'skype:event:account'\n",
    "\n",
    "  def __init__(\n",
    "      self, timestamp, usage, identifier, full_name, display_name, email,\n",
    "      country):\n",
    "    \"\"\"Initialize the event.\n",
    "\n",
    "    Args:\n",
    "      timestamp: The POSIX timestamp value.\n",
    "      usage: A string containing the description string of the timestamp.\n",
    "      identifier: The row identifier.\n",
    "      full_name: A string containing the full name of the Skype account holder.\n",
    "      display_name: A string containing the chosen display name of the account\n",
    "                    holder.\n",
    "      email: A string containing the registered email address of the account\n",
    "             holder.\n",
    "      country: A string containing the chosen home country of the account\n",
    "               holder.\n",
    "    \"\"\"\n",
    "    super(SkypeAccountEvent, self).__init__(timestamp, usage)\n",
    "\n",
    "    self.offset = identifier\n",
    "    self.username = u'{0:s} <{1:s}>'.format(full_name, display_name)\n",
    "    self.display_name = display_name\n",
    "    self.email = email\n",
    "    self.country = country\n",
    "    self.data_type = self.DATA_TYPE\n",
    "\n",
    "\n",
    "class SkypeSMSEvent(time_events.PosixTimeEvent):\n",
    "  \"\"\"Convenience EventObject for SMS.\"\"\"\n",
    "\n",
    "  DATA_TYPE = 'skype:event:sms'\n",
    "\n",
    "  def __init__(self, row, dst_number):\n",
    "    \"\"\"Read the information related with the SMS.\n",
    "\n",
    "      Args:\n",
    "        row: row form the sql query.\n",
    "          row['time_sms']: timestamp when the sms was send.\n",
    "          row['dstnum_sms']: number which receives the sms.\n",
    "          row['msg_sms']: text send to this sms.\n",
    "        dst_number: phone number where the user send the sms.\n",
    "    \"\"\"\n",
    "    super(SkypeSMSEvent, self).__init__(\n",
    "        row['time_sms'], 'SMS from Skype', self.DATA_TYPE)\n",
    "\n",
    "    self.number = dst_number\n",
    "    self.text = row['msg_sms']\n",
    "\n",
    "\n",
    "class SkypeCallEvent(time_events.PosixTimeEvent):\n",
    "  \"\"\"Convenience EventObject for the calls.\"\"\"\n",
    "\n",
    "  DATA_TYPE = 'skype:event:call'\n",
    "\n",
    "  def __init__(self, timestamp, call_type, user_start_call,\n",
    "               source, destination, video_conference):\n",
    "    \"\"\"Contains information if the call was cancelled, accepted or finished.\n",
    "\n",
    "      Args:\n",
    "        timestamp: the timestamp of the event.\n",
    "        call_type: WAITING, STARTED, FINISHED.\n",
    "        user_start_call: boolean, true indicates that the owner\n",
    "                         account started the call.\n",
    "        source: the account which started the call.\n",
    "        destination: the account which gets the call.\n",
    "        video_conference: boolean, if is true it was a videoconference.\n",
    "    \"\"\"\n",
    "\n",
    "    super(SkypeCallEvent, self).__init__(\n",
    "        timestamp, 'Call from Skype', self.DATA_TYPE)\n",
    "\n",
    "    self.call_type = call_type\n",
    "    self.user_start_call = user_start_call\n",
    "    self.src_call = source\n",
    "    self.dst_call = destination\n",
    "    self.video_conference = video_conference\n",
    "\n",
    "\n",
    "class SkypeTransferFileEvent(time_events.PosixTimeEvent):\n",
    "  \"\"\"Evaluate the action of send a file.\"\"\"\n",
    "\n",
    "  DATA_TYPE = 'skype:event:transferfile'\n",
    "\n",
    "  def __init__(self, row, timestamp, action_type, source, destination):\n",
    "    \"\"\"Actions related with sending files.\n",
    "\n",
    "      Args:\n",
    "        row:\n",
    "          filepath: path from the file.\n",
    "          filename: name of the file.\n",
    "          filesize: size of the file.\n",
    "        timestamp: when the action happens.\n",
    "        action_type: GETSOLICITUDE, SENDSOLICITUDE, ACCEPTED, FINISHED.\n",
    "        source: The account that sent the file.\n",
    "        destination: The account that received the file.\n",
    "    \"\"\"\n",
    "\n",
    "    super(SkypeTransferFileEvent, self).__init__(\n",
    "        timestamp, 'File transfer from Skype', self.DATA_TYPE)\n",
    "\n",
    "    self.offset = row['id']\n",
    "    self.action_type = action_type\n",
    "    self.source = source\n",
    "    self.destination = destination\n",
    "    self.transferred_filepath = row['filepath']\n",
    "    self.transferred_filename = row['filename']\n",
    "    try:\n",
    "      self.transferred_filesize = int(row['filesize'])\n",
    "    except ValueError:\n",
    "      logging.debug(u'Unknown filesize {0:s}'.format(\n",
    "          self.transferred_filename))\n",
    "      self.transferred_filesize = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it really, we only need to worry about filling in the values for the class constants and then create the appropriate call back functions (and potentially create some assistant event objects).\n",
    "\n",
    "Here is part of the code for the Skype parser, it is longer on the site, however for simplicity reasons it only shows one query and the resulting call back function for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SkypePluginFoo(interface.SQLitePlugin):\n",
    "  \"\"\"SQLite plugin for Skype main.db SQlite database file.\"\"\"\n",
    "\n",
    "  # Append foo to the name so this can be registered on the side with the other Skype\n",
    "  # parser. This is also only a partial parser (for simplicity reasons).\n",
    "  NAME = 'skype_foo'\n",
    "\n",
    "  # Provide the description field.\n",
    "  DESCRIPTION = u'Parser for Skype SQLite database files.'\n",
    "\n",
    "  # Queries for building cache. Since we do want to use cache for the Skype plugin\n",
    "  # we define the SQLite commands for it here. There are two cache queries we want\n",
    "  # to perform, one to get destinations from the transfers table and the other to\n",
    "  # get source from the same table.\n",
    "  # Queries for building cache.\n",
    "  QUERY_DEST_FROM_TRANSFER = (\n",
    "      u'SELECT parent_id, partner_handle AS skypeid, '\n",
    "      u'partner_dispname AS skypename FROM transfers')\n",
    "  QUERY_SOURCE_FROM_TRANSFER = (\n",
    "      u'SELECT pk_id, partner_handle AS skypeid, '\n",
    "      u'partner_dispname AS skypename FROM transfers')\n",
    "\n",
    "  # Define the needed queries. We could only have one query here to show the\n",
    "  # plugin and how it works without the extra complexity, but instead all are\n",
    "  # included, to show how a plugin can be expanded to include queries to several\n",
    "  # tables.\n",
    "  # Define the needed queries.\n",
    "  QUERIES = [\n",
    "      ((u'SELECT c.id, c.participants, c.friendlyname AS title, '\n",
    "        u'm.author AS author, m.from_dispname AS from_displayname, '\n",
    "        u'm.body_xml, m.timestamp, c.dialog_partner FROM Chats c, Messages m '\n",
    "        u'WHERE c.name = m.chatname'), u'ParseChat'),\n",
    "      ((u'SELECT id, fullname, given_displayname, emails, '\n",
    "        u'country, profile_timestamp, authreq_timestamp, '\n",
    "        u'lastonline_timestamp, mood_timestamp, sent_authrequest_time, '\n",
    "        u'lastused_timestamp FROM Accounts'), u'ParseAccountInformation'),\n",
    "      ((u'SELECT id, target_numbers AS dstnum_sms, timestamp AS time_sms, '\n",
    "        u'body AS msg_sms FROM SMSes'), u'ParseSMS'),\n",
    "      ((u'SELECT id, partner_handle, partner_dispname, offer_send_list, '\n",
    "        u'starttime, accepttime, finishtime, filepath, filename, filesize, '\n",
    "        u'status, parent_id, pk_id FROM Transfers'), u'ParseFileTransfer'),\n",
    "      ((u'SELECT c.id, cm.guid, c.is_incoming, '\n",
    "        u'cm.call_db_id, cm.videostatus, c.begin_timestamp AS try_call, '\n",
    "        u'cm.start_timestamp AS accept_call, cm.call_duration '\n",
    "        u'FROM Calls c, CallMembers cm '\n",
    "        u'WHERE c.id = cm.call_db_id;'), u'ParseCall')]\n",
    "\n",
    "  # The required tables.\n",
    "  REQUIRED_TABLES = frozenset([\n",
    "      u'Chats', u'Accounts', u'Conversations', u'Contacts', u'SMSes',\n",
    "      u'Transfers', u'CallMembers', u'Calls'])\n",
    "\n",
    "  def ParseAccountInformation(\n",
    "      self, parser_mediator, row, query=None, **unused_kwargs):\n",
    "    \"\"\"Parses the Accounts database.\n",
    "\n",
    "    Args:\n",
    "      parser_mediator: A parser mediator object (instance of ParserMediator).\n",
    "      row: The row resulting from the query.\n",
    "      query: Optional query string. The default is None.\n",
    "    \"\"\"\n",
    "    # Note that pysqlite does not accept a Unicode string in row['string'] and\n",
    "    # will raise \"IndexError: Index must be int or string\".\n",
    "\n",
    "    if row['profile_timestamp']:\n",
    "      event_object = SkypeAccountEvent(\n",
    "          row['profile_timestamp'], u'Profile Changed', row['id'],\n",
    "          row['fullname'], row['given_displayname'], row['emails'],\n",
    "          row['country'])\n",
    "      parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "    if row['authreq_timestamp']:\n",
    "      event_object = SkypeAccountEvent(\n",
    "          row['authreq_timestamp'], u'Authenticate Request', row['id'],\n",
    "          row['fullname'], row['given_displayname'], row['emails'],\n",
    "          row['country'])\n",
    "      parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "    if row['lastonline_timestamp']:\n",
    "      event_object = SkypeAccountEvent(\n",
    "          row['lastonline_timestamp'], u'Last Online', row['id'],\n",
    "          row['fullname'], row['given_displayname'], row['emails'],\n",
    "          row['country'])\n",
    "      parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "    if row['mood_timestamp']:\n",
    "      event_object = SkypeAccountEvent(\n",
    "          row['mood_timestamp'], u'Mood Event', row['id'],\n",
    "          row['fullname'], row['given_displayname'], row['emails'],\n",
    "          row['country'])\n",
    "      parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "    if row['sent_authrequest_time']:\n",
    "      event_object = SkypeAccountEvent(\n",
    "          row['sent_authrequest_time'], u'Auth Request Sent', row['id'],\n",
    "          row['fullname'], row['given_displayname'], row['emails'],\n",
    "          row['country'])\n",
    "      parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "    if row['lastused_timestamp']:\n",
    "      event_object = SkypeAccountEvent(\n",
    "          row['lastused_timestamp'], u'Last Used', row['id'],\n",
    "          row['fullname'], row['given_displayname'], row['emails'],\n",
    "          row['country'])\n",
    "      parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "  def ParseChat(self, parser_mediator, row, query=None, **unused_kwargs):\n",
    "    \"\"\"Parses a chat message row.\n",
    "\n",
    "    Args:\n",
    "      parser_mediator: A parser mediator object (instance of ParserMediator).\n",
    "      row: The row resulting from the query.\n",
    "      query: Optional query string. The default is None.\n",
    "    \"\"\"\n",
    "    # Note that pysqlite does not accept a Unicode string in row['string'] and\n",
    "    # will raise \"IndexError: Index must be int or string\".\n",
    "\n",
    "    to_account = u''\n",
    "    accounts = []\n",
    "    participants = row['participants'].split(' ')\n",
    "    for participant in participants:\n",
    "      if participant != row['author']:\n",
    "        accounts.append(participant)\n",
    "    to_account = u', '.join(accounts)\n",
    "\n",
    "    if not to_account:\n",
    "      if row['dialog_partner']:\n",
    "        to_account = row['dialog_partner']\n",
    "      else:\n",
    "        to_account = u'Unknown User'\n",
    "\n",
    "    event_object = SkypeChatEvent(row, to_account)\n",
    "    parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "  def ParseSMS(self, parser_mediator, row, query=None, **unused_kwargs):\n",
    "    \"\"\"Parse SMS.\n",
    "\n",
    "    Args:\n",
    "      parser_mediator: A parser mediator object (instance of ParserMediator).\n",
    "      row: The row resulting from the query.\n",
    "      query: Optional query string. The default is None.\n",
    "    \"\"\"\n",
    "    # Note that pysqlite does not accept a Unicode string in row['string'] and\n",
    "    # will raise \"IndexError: Index must be int or string\".\n",
    "\n",
    "    dst_number = row['dstnum_sms'].replace(u' ', u'')\n",
    "\n",
    "    event_object = SkypeSMSEvent(row, dst_number)\n",
    "    parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "  def ParseCall(self, parser_mediator, row, query=None, **unused_kwargs):\n",
    "    \"\"\"Parse the calls taking into accounts some rows.\n",
    "\n",
    "    Args:\n",
    "      parser_mediator: A parser mediator object (instance of ParserMediator).\n",
    "      row: The row resulting from the query.\n",
    "      query: Optional query string. The default is None.\n",
    "    \"\"\"\n",
    "    # Note that pysqlite does not accept a Unicode string in row['string'] and\n",
    "    # will raise \"IndexError: Index must be int or string\".\n",
    "\n",
    "    try:\n",
    "      aux = row['guid']\n",
    "      if aux:\n",
    "        aux_list = aux.split(u'-')\n",
    "        src_aux = aux_list[0]\n",
    "        dst_aux = aux_list[1]\n",
    "      else:\n",
    "        src_aux = u'Unknown [no GUID]'\n",
    "        dst_aux = u'Unknown [no GUID]'\n",
    "    except IndexError:\n",
    "      src_aux = u'Unknown [{0:s}]'.format(row['guid'])\n",
    "      dst_aux = u'Unknown [{0:s}]'.format(row['guid'])\n",
    "\n",
    "    if row['is_incoming'] == u'0':\n",
    "      user_start_call = True\n",
    "      source = src_aux\n",
    "      if row['ip_address']:\n",
    "        destination = u'{0:s} <{1:s}>'.format(dst_aux, row['ip_address'])\n",
    "      else:\n",
    "        destination = dst_aux\n",
    "    else:\n",
    "      user_start_call = False\n",
    "      source = src_aux\n",
    "      destination = dst_aux\n",
    "\n",
    "    if row['videostatus'] == u'3':\n",
    "      video_conference = True\n",
    "    else:\n",
    "      video_conference = False\n",
    "\n",
    "    event_object = SkypeCallEvent(\n",
    "        row['try_call'], u'WAITING', user_start_call, source, destination,\n",
    "        video_conference)\n",
    "    parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "    if row['accept_call']:\n",
    "      event_object = SkypeCallEvent(\n",
    "          row['accept_call'], u'ACCEPTED', user_start_call, source,\n",
    "          destination, video_conference)\n",
    "      parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "      if row['call_duration']:\n",
    "        try:\n",
    "          timestamp = int(row['accept_call']) + int(row['call_duration'])\n",
    "          event_object = SkypeCallEvent(\n",
    "              timestamp, u'FINISHED', user_start_call, source, destination,\n",
    "              video_conference)\n",
    "          parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "        except ValueError:\n",
    "          logging.debug((\n",
    "              u'[{0:s}] Unable to determine when the call {1:s} was '\n",
    "              u'finished.').format(self.NAME, row['id']))\n",
    "\n",
    "  def ParseFileTransfer(\n",
    "      self, parser_mediator, row, cache=None, database=None, query=None,\n",
    "      **unused_kwargs):\n",
    "    \"\"\"Parse the transfer files.\n",
    "\n",
    "     There is no direct relationship between who sends the file and\n",
    "     who accepts the file.\n",
    "\n",
    "    Args:\n",
    "      parser_mediator: A parser mediator object (instance of ParserMediator).\n",
    "      row: the row with all information related with the file transfers.\n",
    "      query: Optional query string. The default is None.\n",
    "      cache: a cache object (instance of SQLiteCache).\n",
    "      database: A database object (instance of SQLiteDatabase).\n",
    "    \"\"\"\n",
    "    # Note that pysqlite does not accept a Unicode string in row['string'] and\n",
    "    # will raise \"IndexError: Index must be int or string\".\n",
    "\n",
    "    source_dict = cache.GetResults(u'source')\n",
    "    if not source_dict:\n",
    "      results = database.Query(self.QUERY_SOURCE_FROM_TRANSFER)\n",
    "\n",
    "      # Note that pysqlite does not accept a Unicode string in row['string'] and\n",
    "      # will raise \"IndexError: Index must be int or string\".\n",
    "      cache.CacheQueryResults(\n",
    "          results, 'source', 'pk_id', ('skypeid', 'skypename'))\n",
    "      source_dict = cache.GetResults(u'source')\n",
    "\n",
    "    dest_dict = cache.GetResults(u'destination')\n",
    "    if not dest_dict:\n",
    "      results = database.Query(self.QUERY_DEST_FROM_TRANSFER)\n",
    "\n",
    "      # Note that pysqlite does not accept a Unicode string in row['string'] and\n",
    "      # will raise \"IndexError: Index must be int or string\".\n",
    "      cache.CacheQueryResults(\n",
    "          results, 'destination', 'parent_id', ('skypeid', 'skypename'))\n",
    "      dest_dict = cache.GetResults(u'destination')\n",
    "\n",
    "    source = u'Unknown'\n",
    "    destination = u'Unknown'\n",
    "\n",
    "    if row['parent_id']:\n",
    "      destination = u'{0:s} <{1:s}>'.format(\n",
    "          row['partner_handle'], row['partner_dispname'])\n",
    "      skype_id, skype_name = source_dict.get(row['parent_id'], [None, None])\n",
    "      if skype_name:\n",
    "        source = u'{0:s} <{1:s}>'.format(skype_id, skype_name)\n",
    "    else:\n",
    "      source = u'{0:s} <{1:s}>'.format(\n",
    "          row['partner_handle'], row['partner_dispname'])\n",
    "\n",
    "      if row['pk_id']:\n",
    "        skype_id, skype_name = dest_dict.get(row['pk_id'], [None, None])\n",
    "        if skype_name:\n",
    "          destination = u'{0:s} <{1:s}>'.format(skype_id, skype_name)\n",
    "\n",
    "    if row['status'] == 8:\n",
    "      if row['starttime']:\n",
    "        event_object = SkypeTransferFileEvent(\n",
    "            row, row['starttime'], u'GETSOLICITUDE', source, destination)\n",
    "        parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "      if row['accepttime']:\n",
    "        event_object = SkypeTransferFileEvent(\n",
    "            row, row['accepttime'], u'ACCEPTED', source, destination)\n",
    "        parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "      if row['finishtime']:\n",
    "        event_object = SkypeTransferFileEvent(\n",
    "            row, row['finishtime'], u'FINISHED', source, destination)\n",
    "        parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "    elif row['status'] == 2 and row['starttime']:\n",
    "      event_object = SkypeTransferFileEvent(\n",
    "          row, row['starttime'], u'SENDSOLICITUDE', source, destination)\n",
    "      parser_mediator.ProduceEvent(event_object, query=query)\n",
    "\n",
    "\n",
    "# And finally we need to register this plugin.\n",
    "sqlite_parser.SQLiteParser.RegisterPlugin(SkypePluginFoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**optional code segment**] If you make some modifications to the class above you need to first de-register it before you can register it again. To be able to de-register it use the code block below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPTIONAL CODE BLOCK !! DON'T EXECUTE UNLESS YOU HAVE MADE SOME \n",
    "# CHANGES TO THE PARSER CODE AND WANT TO REGISTER IT AGAIN!!!\n",
    "sqlite_parser.SQLiteParser.DeregisterPlugin(SkypePluginFoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the Formatter\n",
    "\n",
    "Have you ever noticed the message string when you print out an event?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plaso.formatters import manager as formatter_manager\n",
    "from plaso.formatters import mediator as formatter_mediator\n",
    "\n",
    "\n",
    "# Import the skype formatter.\n",
    "from plaso.formatters import skype as skype_formatter\n",
    "\n",
    "timestamp_now = timelib.Timestamp.GetNow()\n",
    "timestamp_posix = timestamp_now // 1000000\n",
    "\n",
    "# Let's create a dummy event.\n",
    "\n",
    "# For we need to fake the \"row\" object:\n",
    "dummy_row = {\n",
    "    'timestamp': timestamp_posix,\n",
    "    'title': 'This is a good title.',\n",
    "    'body_xml': 'Please pick up now...',\n",
    "    'from_displayname': 'Secret Caller',\n",
    "    'author': 'Me, myself and Irene'}\n",
    "    \n",
    "dummy_event = SkypeChatEvent(dummy_row, 'le baron')\n",
    "\n",
    "# And print the string.\n",
    "print dummy_event.GetString()\n",
    "\n",
    "# And to re-iterate, let's print the message string.\n",
    "formatter_mediator_object = formatter_mediator.FormatterMediator()\n",
    "message_string, _ = formatter_manager.FormattersManager.GetMessageStrings(formatter_mediator_object, dummy_event)\n",
    "\n",
    "print u'MESSAGE STRING: {}'.format(message_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice that in the event above you never really told it how to construct this message string? How does the tool then know how to print it out?\n",
    "\n",
    "That is the purpose of the formatter. The formatter is a simple class that defines what attributes to use and how they are put together to form this message string.\n",
    "\n",
    "You're going to need one for any plugin or parser you create (or more precisely any data type that there exist).\n",
    "\n",
    "The way the formatter works is that it looks at the data_type attribute in the EventObject and matches that to the formatters DATA_TYPE attribute. If they are the same, then the formatter proceeds to processing that EventObject and construct the messsage string.\n",
    "\n",
    "Formatters go in separate files under plaso/formatters.  \n",
    "\n",
    "For the most part, you're just setting some values with formats.  You'll want to set up structures that you want to see in your timeline.\n",
    "\n",
    "Most importantly (to re-iterate), the **DATA_TYPE** must match the data_type attribute from the EventObject from the last section.  Watch out for typos here -- there is no warning.\n",
    "\n",
    "There are two formatters that you can use, the simple **EventFormatter** and the **ConditionalEventFormatter**. The former should only be used if you are absolutely sure all the attributes mentioned there are going to be set for each and every event object created. That means that for the vast majority of the formatters the ConditionalEventFormatter should be the formatter of choice.\n",
    "\n",
    "There are two class constants that should always be set, irrelevant of the choice of formatters:\n",
    "\n",
    "+ **SOURCE_SHORT**: This should match one of the common sources, eg. LOG, WEBHIST, etc. This should closely correspond to the TLN format by H. Carvey as a short description of the source, almost like a short name for the category of the source.\n",
    "+ **SOURCE_LONG**: Since the category itself is not sufficient to describe the source we have an extra field called SOURCE_LONG that further defines that, for instance a browser history extracted from Chrome browser will have the source short set to WEBHIST, indicating that this comes from a web history, but the SOURCE_LONG contains the text \"Chrome History\", setting that apart from other browsers.\n",
    "\n",
    "For the simple EventFormatter two class constants have to be set (or at least one):\n",
    "\n",
    "+ **FORMAT_STRING**: An unicode string that contains formatting information, place all attribute names in {}. This is just a typical Python formatting string, so all typical [rules](http://docs.python.org/2/library/string.html#formatspec) apply. Timestamp, filename/path, username, hostname, etc information is presented in other fields and should not be a part of the message string.\n",
    "+ **FORMAT_STRING_SHORT**: This is only needed when you think that the resulting message string may exceed 80 characters in with and you don't want that to be shorten, as in you don't want the short message string to just contain the first 77 characters of the longer version you can construct your own condensed one.\n",
    "\n",
    "If you use the conditional formatter you need to define the following class constants:\n",
    "\n",
    "+ **FORMAT_STRING_PIECES**: The same as the FORMAT_STRING, except that this is a list and only one attribute name should be defined per entry. If an attribute is not set in the event object then that particular entry in the list will be omitted.\n",
    "+ **FORMAT_STRING_SHORT_PIECES**: Same as the FORMAT_STRING_SHORT except in the same format as FORMAT_STRING_PIECES, that is as a list.\n",
    "\n",
    "For our purposes we use the skype_formatter here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PrintClassHelp(skype_formatter.SkypeChatFormatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test The Plugin\n",
    "\n",
    "It is very important to test the plugin, to see if it can at least parse our sample dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the File Using The Plugin\n",
    "\n",
    "We can use the code below to test our parsing, to see if the plugin is capable of parsing registry key we provided it with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plaso.engine import knowledge_base\n",
    "from plaso.engine import queue\n",
    "from plaso.engine import single_process\n",
    "\n",
    "from plaso.lib import errors\n",
    "from dfvfs.lib import definitions\n",
    "\n",
    "from plaso.parsers import mediator as parsers_mediator\n",
    "\n",
    "from dfvfs.path import factory as path_spec_factory\n",
    "from dfvfs.resolver import resolver as path_spec_resolver\n",
    "\n",
    "# A library for testing parsers\n",
    "from tests.parsers import test_lib as parsers_test_lib\n",
    "\n",
    "# Create the plugin object.\n",
    "test_plugin = SkypePluginFoo()\n",
    "\n",
    "print u'Parsing file using: {}'.format(test_plugin.plugin_name)\n",
    "\n",
    "# Create a parser mediator and the necessary queues.\n",
    "event_queue = single_process.SingleProcessQueue()\n",
    "event_queue_producer = single_process.SingleProcessItemQueueProducer(event_queue)\n",
    "\n",
    "parser_error_queue = single_process.SingleProcessQueue()\n",
    "parser_error_queue_producer = single_process.SingleProcessItemQueueProducer(\n",
    "      parser_error_queue)\n",
    "\n",
    "knowledge_base_object = knowledge_base.KnowledgeBase()\n",
    "this_parser_mediator = parsers_mediator.ParserMediator(\n",
    "    event_queue_producer, parser_error_queue_producer, knowledge_base_object)\n",
    "\n",
    "# Now we can start parsing the file using the plugin.\n",
    "test_plugin.Process(parser_mediator=this_parser_mediator, cache=database_cache, database=database)\n",
    "\n",
    "# Set up a consumer to read events emited by our plugin.\n",
    "event_queue_consumer = parsers_test_lib.TestItemQueueConsumer(event_queue)\n",
    "# Read all the events.\n",
    "event_queue_consumer.ConsumeItems()\n",
    "event_objects = event_queue_consumer.event_objects\n",
    "\n",
    "print u'Processing of SQLite database is done.'\n",
    "print u'Able to extract: {} events from the database.'.format(len(event_objects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the event objects that we managed to extract from this plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print out the content of the extracted events.\n",
    "for index, event_object in enumerate(event_objects):\n",
    "  print u'*' * 80\n",
    "  print u'    EVENT NUMBER: {}'.format(index)\n",
    "  print u'-'*80\n",
    "  print u'Event:'\n",
    "  print event_object.GetString()\n",
    "  print u''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the Tests\n",
    "\n",
    "Unit tests are designed to make sure your code is doing what you intended it to do, as well as to let other people know when their refactor broke your code.  This will also assist you when you are writing your code by doing a sanity check on your plugin to make sure it works the way you expect it to.\n",
    "\n",
    "The test go in their own file, in this case the file tests//sqlite_plugins/skype.py.\n",
    "\n",
    "For the tests to work the formatter needs to imported. However since the formatter is typically named the same name as the actual plugin (or parser) we may need to import the formatter as a separate name. And since you don't actually use the formatter directly in the file you end up with needing a pylint statement to suppress error messages during linting.  The other imports you'll see through out this code lab. But since everything is in the same namespace here we don't really need to import the formatter, but this is typically added:\n",
    "\n",
    "    # pylint: disable-msg=unused-import\n",
    "    from tests.formatters import skype as skype_formatter\n",
    "\n",
    "The pylint statement needs to be there to make sure that pylint does not complain about an unused import since we are not directly using the formatter, we are just importing it so that it gets registered (othwerise it will not work).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TestCase and setUp()\n",
    "\n",
    "For a plugin test we will use the appropriate plugin test library, in this case the tests/parsers/sqlite_plugins/test_lib (or test_lib.SQLitePluginTestCase).  This is a simple class that inherits from the plaso parser test lib (which in turn inherits from the unittest.TestCase class), and adds a few functions to make it easier to test SQLite database plugins. You may want to add a setUp() function to open the sample file and set any other variables you expect to need.  \n",
    "\n",
    "For a SQlite database plugin you typically need to build a cache (if one is needed for the plugin), open the test file from a path (using _GetTestFilePath) and call the \"_ParseDatabaseFileWithPlugin\" function of the test lib.\n",
    "\n",
    "Let's first look at what functions are available to us in the SQLite test library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tests.parsers.sqlite_plugins import test_lib as sqlite_test_lib\n",
    "\n",
    "PrintClassHelp(sqlite_test_lib.SQLitePluginTestCase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the setUp() function for this class definition:\n",
    "\n",
    "    class SkypePluginTest(test_lib.SQLitePluginTestCase):\n",
    "      \"\"\"Tests for the Skype main.db history database plugin.\"\"\"\n",
    "\n",
    "      def setUp(self):\n",
    "\n",
    "While we're setting up the boilerplate of the test, let's add the main function to the bottom of the file.  Then we can run the test on its own.\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "     unittest.main()\n",
    "\n",
    "### Writing the Test\n",
    "\n",
    "The outline of the main test is to create and run the plugin, then check that the plugin results are correct.  You should check a variety of attributes in one row and something about the extracted events in general.\n",
    "\n",
    "The test needs to start with the word \"test\".  Let's use testProcess() (since that is what we are testing, the Process function fo the plugin).  The assertions should include:\n",
    "\n",
    "+ How many entries were created?\n",
    "+ For entry[1], is the timestame, username, and full_path correct?\n",
    "+ For entry[1], are the message strings formatted correctly?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plaso.formatters import skype as skype_formatter\n",
    "from plaso.lib import timelib\n",
    "from plaso.parsers.sqlite_plugins import skype as skype_plugin\n",
    "\n",
    "class SkypePluginTest(sqlite_test_lib.SQLitePluginTestCase):\n",
    "  \"\"\"Tests for the Skype main.db history database plugin.\"\"\"\n",
    "\n",
    "  def setUp(self):\n",
    "    \"\"\"Sets up the needed objects used throughout the test.\"\"\"\n",
    "    self._plugin = skype_plugin.SkypePlugin()\n",
    "\n",
    "  def testProcess(self):\n",
    "    \"\"\"Tests the Process function on a Skype History database file.\n",
    "\n",
    "      The History file contains 24 events:\n",
    "          4 call events\n",
    "          4 transfers file events\n",
    "          1 sms events\n",
    "         15 chat events\n",
    "\n",
    "      Events used:\n",
    "        id = 16 -> SMS\n",
    "        id = 22 -> Call\n",
    "        id = 18 -> File\n",
    "        id =  1 -> Chat\n",
    "        id = 14 -> ChatRoom\n",
    "    \"\"\"\n",
    "    # In the actual test file we would use the _GetTestFilePath but here we already\n",
    "    # have a test file.\n",
    "    # test_file = self._GetTestFilePath(['skype_main.db'])\n",
    "    test_file = test_database_path\n",
    "    \n",
    "    cache = sqlite_parser.SQLiteCache()\n",
    "    event_queue_consumer = self._ParseDatabaseFileWithPlugin(\n",
    "        self._plugin, test_file, cache)\n",
    "    event_objects = self._GetEventObjectsFromQueue(event_queue_consumer)\n",
    "\n",
    "    calls = 0\n",
    "    files = 0\n",
    "    sms = 0\n",
    "    chats = 0\n",
    "    for event_object in event_objects:\n",
    "      if event_object.data_type == 'skype:event:call':\n",
    "        calls += 1\n",
    "      if event_object.data_type == 'skype:event:transferfile':\n",
    "        files += 1\n",
    "      if event_object.data_type == 'skype:event:sms':\n",
    "        sms += 1\n",
    "      if event_object.data_type == 'skype:event:chat':\n",
    "        chats += 1\n",
    "\n",
    "    self.assertEquals(len(event_objects), 24)\n",
    "    self.assertEquals(files, 4)\n",
    "    self.assertEquals(sms, 1)\n",
    "    self.assertEquals(chats, 15)\n",
    "    self.assertEquals(calls, 3)\n",
    "\n",
    "    # TODO: Split this up into separate functions for testing each type of\n",
    "    # event, eg: testSMS, etc.\n",
    "    sms_event_object = event_objects[16]\n",
    "    call_event_object = event_objects[22]\n",
    "    event_file = event_objects[18]\n",
    "    chat_event_object = event_objects[1]\n",
    "    chat_room_event_object = event_objects[14]\n",
    "\n",
    "    # Test cache processing and format strings.\n",
    "    expected_msg = (\n",
    "        u'Source: gen.beringer <Gen Beringer> Destination: '\n",
    "        u'european.bbq.competitor <European BBQ> File: secret-project.pdf '\n",
    "        u'[SENDSOLICITUDE]')\n",
    "\n",
    "    self._TestGetMessageStrings(\n",
    "        event_objects[17], expected_msg, expected_msg[0:77] + '...')\n",
    "\n",
    "    expected_timestamp = timelib.Timestamp.CopyFromString(\n",
    "        '2013-07-01 22:14:22')\n",
    "    self.assertEquals(sms_event_object.timestamp, expected_timestamp)\n",
    "    text_sms = (u'If you want I can copy '\n",
    "                u'some documents for you, '\n",
    "                u'if you can pay it... ;)')\n",
    "    self.assertEquals(sms_event_object.text, text_sms)\n",
    "    number = u'+34123456789'\n",
    "    self.assertEquals(sms_event_object.number, number)\n",
    "\n",
    "    expected_timestamp = timelib.Timestamp.CopyFromString(\n",
    "        '2013-10-24 21:49:35')\n",
    "    self.assertEquals(event_file.timestamp, expected_timestamp)\n",
    "\n",
    "    action_type = u'GETSOLICITUDE'\n",
    "    self.assertEquals(event_file.action_type, action_type)\n",
    "    source = u'gen.beringer <Gen Beringer>'\n",
    "    self.assertEquals(event_file.source, source)\n",
    "    destination = u'european.bbq.competitor <European BBQ>'\n",
    "    self.assertEquals(event_file.destination, destination)\n",
    "    transferred_filename = u'secret-project.pdf'\n",
    "    self.assertEquals(event_file.transferred_filename, transferred_filename)\n",
    "    filepath = u'/Users/gberinger/Desktop/secret-project.pdf'\n",
    "    self.assertEquals(event_file.transferred_filepath, filepath)\n",
    "    self.assertEquals(event_file.transferred_filesize, 69986)\n",
    "\n",
    "    expected_timestamp = timelib_test.CopyStringToTimestamp(\n",
    "        '2013-07-30 21:27:11')\n",
    "    self.assertEquals(chat_event_object.timestamp, expected_timestamp)\n",
    "\n",
    "    title = u'European Competitor | need to know if you got it..'\n",
    "    self.assertEquals(chat_event_object.title, title)\n",
    "    expected_msg = u'need to know if you got it this time.'\n",
    "    self.assertEquals(chat_event_object.text, expected_msg)\n",
    "    from_account = u'Gen Beringer <gen.beringer>'\n",
    "    self.assertEquals(chat_event_object.from_account, from_account)\n",
    "    self.assertEquals(chat_event_object.to_account, u'european.bbq.competitor')\n",
    "\n",
    "    expected_timestamp = timelib_test.CopyStringToTimestamp(\n",
    "        '2013-10-27 15:29:19')\n",
    "    self.assertEquals(chat_room_event_object.timestamp, expected_timestamp)\n",
    "\n",
    "    title = u'European Competitor, Echo123'\n",
    "    self.assertEquals(chat_room_event_object.title, title)\n",
    "    expected_msg = u'He is our new employee'\n",
    "    self.assertEquals(chat_room_event_object.text, expected_msg)\n",
    "    from_account = u'European Competitor <european.bbq.competitor>'\n",
    "    self.assertEquals(chat_room_event_object.from_account, from_account)\n",
    "    to_account = u'gen.beringer, echo123'\n",
    "    self.assertEquals(chat_room_event_object.to_account, to_account)\n",
    "\n",
    "    expected_timestamp = timelib_test.CopyStringToTimestamp(\n",
    "        '2013-07-01 22:12:17')\n",
    "    self.assertEquals(call_event_object.timestamp, expected_timestamp)\n",
    "\n",
    "    self.assertEquals(call_event_object.dst_call, u'european.bbq.competitor')\n",
    "    self.assertEquals(call_event_object.src_call, u'gen.beringer')\n",
    "    self.assertEquals(call_event_object.user_start_call, False)\n",
    "    self.assertEquals(call_event_object.video_conference, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Tests\n",
    "\n",
    "How will you know what the format string should look like?  Well, it's time to run the code we have.  Typically the plugin needs to be \"compiled\" before the test will be able to import it, so we need to make sure the plugin gets picked up for compilation.\n",
    "\n",
    "To do this, you would edit plaso/parsers/sqlite\\_plugins/\\_\\_init\\_\\_.py and add an import statement for your new plugin.\n",
    "\n",
    "Normally to run the tests you would either need to run:\n",
    "\n",
    "    python run_tests.py\n",
    "\n",
    "Or to compile:\n",
    "\n",
    "    python setup.py build && sudo python setup.py install\n",
    "\n",
    "And then you can run the test directly using:\n",
    "\n",
    "    python tests/parsers/sqlite_plugins/skype.py\n",
    "\n",
    "Rinse and repeat as you write the tests.  If you change the parser, you need to recompile.  If you just change the test, you don't.\n",
    "\n",
    "**However** since we are writing this in our notebook we just need to make sure we've run all the previous code segments, and if you make changes, just re-run it.\n",
    "\n",
    "To run the test itself, execute the below code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "my_suite = unittest.TestSuite()\n",
    "my_suite.addTest(SkypePluginTest('testProcess'))\n",
    "\n",
    "results = unittest.TextTestRunner(verbosity=3).run(my_suite)\n",
    "\n",
    "if results.errors:\n",
    "  print u'Errors came up while trying to run test.'\n",
    "  for error in results.errors:\n",
    "    if isinstance(error, basestring):\n",
    "      print error\n",
    "    else:\n",
    "      for sub_error in error:\n",
    "        print sub_error\n",
    "elif results.failures:\n",
    "  print u'Failures came up while trying to run test.'\n",
    "  for failure in results.failures:\n",
    "    if isinstance(failure, basestring):\n",
    "      print failure\n",
    "    else:\n",
    "      for sub_failure in failure:\n",
    "        print sub_failure\n",
    "else:\n",
    "  print u'All came out clean.'\n",
    "  print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well you should have a fully functioning plugin by now, ready to parse every boot execut registry key you may encounter.  \n",
    "\n",
    "You can start playing around and making changes to the plugin, to see what happens when changes are introduced, or continue and create a new plugin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have gone through step-by-step how an example SQLite database plugin is created. It is time to take what we've learned so far and create a new plugin.  \n",
    "\n",
    "**ATM** there is no example assignment for this codelab, like there is for the other codelabs. The assignment is therefore to create a new plugin from scratch for a SQLite database of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "During our test code we created a temporary file, that we may want to delete. To delete it, use the code below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if test_database_path:\n",
    "  os.remove(test_database_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
